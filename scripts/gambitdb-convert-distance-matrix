#!/usr/bin/env python3
import pandas
import numpy
import argparse

def convert_matrix(csv_path, npy_path, index_path):
    """
    Converts a large pairwise distance matrix from CSV format to a NumPy .npy file
    and a separate index file, processing the CSV in chunks to conserve memory.
    This version includes robust error checking for malformed CSV files.
    """
    print("Reading file to get index and dimensions...")

    # Read the header to get the column labels.
    # We slice [1:] because the first column name belongs to the index.
    column_labels = pandas.read_csv(csv_path, nrows=0).columns.tolist()[1:]
    num_columns = len(column_labels)

    # Read just the first column (the index) to get the row labels.
    # We skip the header row to only get data.
    row_labels = pandas.read_csv(csv_path, usecols=[0], skiprows=1, header=None).iloc[:,0].tolist()
    num_rows = len(row_labels)
    
    if num_rows != num_columns:
        print(f"Warning: Matrix may not be square! Detected {num_rows} rows and {num_columns} data columns.")
        print("This can happen if the row/column labels in the CSV are not perfectly matched.")

    # The index for the matrix is the list of row labels.
    full_index = row_labels
    print(f"Matrix dimensions: {num_rows} rows x {num_columns} columns")

    print(f"Saving index to {index_path}...")
    with open(index_path, 'w') as f:
        for item in full_index:
            f.write(f"{item}\n")

    # Create a memory-mapped file on disk.
    print(f"Creating memory-mapped file at {npy_path}...")
    fp = numpy.memmap(npy_path, dtype='float32', mode='w+', shape=(num_rows, num_columns))

    # Process the CSV in chunks
    chunksize = 500
    num_chunks = (num_rows + chunksize - 1) // chunksize
    
    print(f"Processing {num_rows} rows in {num_chunks} chunks of size {chunksize}...")
    
    # Use an iterator to process the file chunk by chunk.
    # index_col=0 tells pandas to treat the first column as the index for each chunk.
    # We let pandas infer the dtype first and then cast to float32, which is more robust.
    reader = pandas.read_csv(csv_path, index_col=0, chunksize=chunksize, iterator=True)
    
    for i, chunk in enumerate(reader):
        start_row = i * chunksize
        end_row = start_row + len(chunk)
        print(f"  ... processing rows {start_row} to {end_row-1}")
        
        # Ensure the read chunk has the expected number of columns
        if chunk.shape[1] != num_columns:
            raise ValueError(
                f"Chunk {i} has {chunk.shape[1]} columns, but {num_columns} were expected. "
                f"Please check for formatting errors (e.g., incorrect delimiters) in the CSV file "
                f"around row {start_row + 2}."
            )

        try:
            # Convert chunk to float32 and write to the memory-mapped file.
            fp[start_row:end_row, :] = chunk.values.astype(numpy.float32)
        except ValueError:
            # If conversion fails, iterate through the chunk to find the exact problematic cell.
            for row_idx, row in chunk.iterrows():
                for col_name, value in row.items():
                    try:
                        float(value)
                    except (ValueError, TypeError):
                        print("\n" + "="*80)
                        print(f"ERROR: Could not convert value to a float.")
                        print(f"Please inspect your CSV file for formatting errors.")
                        print(f" -> Problematic Value: '{value}'")
                        print(f" -> Found in Row Index: '{row_idx}'")
                        print(f" -> Found in Column: '{col_name}'")
                        # Estimate line number: start of chunk + chunk row location + header line + 1-based index
                        line_in_chunk = chunk.index.get_loc(row_idx)
                        estimated_line = start_row + line_in_chunk + 2
                        print(f" -> Approximate Line Number in CSV: {estimated_line}")
                        print("="*80)
                        raise
            # Re-raise original error if our detailed check didn't find the cause.
            raise
            
    # Ensure all data is written to disk and close the file.
    fp.flush()
    del fp
    
    print("\nConversion complete.")
    print(f"NumPy matrix saved to: {npy_path}")
    print(f"Index labels saved to: {index_path}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="Convert a large CSV distance matrix to a memory-mappable .npy format and a separate index file.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument("csv_file", help="Path to the input CSV distance matrix.")
    parser.add_argument("npy_file", help="Path for the output .npy matrix file.")
    parser.add_argument("index_file", help="Path for the output index text file.")
    args = parser.parse_args()
    
    convert_matrix(args.csv_file, args.npy_file, args.index_file)