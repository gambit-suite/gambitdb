#!/usr/bin/env python3
import argparse
import numpy as np
import sqlite3
import os
import shutil

parser = argparse.ArgumentParser(
    description = 'Given two Gambit signatures files, merge them and return a new file.',
    usage = 'gambit-merge-signatures [options]',
    formatter_class=argparse.ArgumentDefaultsHelpFormatter)

# Required input files
parser.add_argument('signatures_main_filename', help='A signatures .h5 file created by gambit signatures', type=str)
parser.add_argument('database_main_filename', help='An SQLite database', type=str)
parser.add_argument('signatures_patch_filename', help='A signatures .h5 file created by gambit signatures', type=str)
parser.add_argument('database_patch_filename', help='An SQLite database', type=str)

# Output
parser.add_argument('--signatures_output_filename', '-s', help='Output filename for genome signatures', default = 'patched_database.gs', type=str)
parser.add_argument('--database_output_filename', '-d', help='Output filename for database', default = 'patched_database.gdb', type=str)

parser.add_argument('--verbose', '-v', action='store_true', help='Turn on verbose output', default = False)
options = parser.parse_args()

# copy the database so we dont modify the original
shutil.copy(options.database_main_filename, options.database_output_filename)

# Connect to the database
main_db_connection = sqlite3.connect(options.database_main_filename)
patch_db_connection = sqlite3.connect(options.database_patch_filename)

# Retrieve patch data
patch_genomes = [row.key for row in patch_db_connection.execute("SELECT key FROM genomes")]
patch_taxa = [row.key for row in patch_db_connection.execute("SELECT name FROM taxa")]

# Lookup main database for corresponding taxa and genomes
# we are going to delete rows so store the ids in a list to help with manipulations (could do a lot of this in join statements)
main_genome_id = [row.genome_id for row in main_db_connection.execute("SELECT genome_id FROM genome_annotation WHERE name IN (?)", patch_taxa)]
main_taxon_id = [row.taxon_id for row in main_db_connection.execute("SELECT taxon_id FROM genome_annotation WHERE name IN (?)", patch_taxa)]

main_genome_accessions_to_remove = [row.key for row in main_db_connection.execute("SELECT key FROM genomes WHERE name IN (?)", main_genome_id)]
# merge the patch_genomes and main_genome_accessions_to_remove lists and remove duplicates
genome_accessions_to_remove = list(set(patch_genomes + main_genome_accessions_to_remove))

main_genome_ids_to_remove = [row.key for row in main_db_connection.execute("SELECT id FROM genomes WHERE name IN (?)", genome_accessions_to_remove)]

# remove genomes and taxa from main database
main_db_connection.execute("DELETE FROM genomes WHERE key IN (?)", main_genome_ids_to_remove)
main_db_connection.execute("DELETE FROM genome_annotation WHERE genome_id IN (?)", main_genome_ids_to_remove)
main_db_connection.execute("DELETE FROM genome_annotation WHERE taxon_id IN (?)", main_taxon_id)
main_db_connection.execute("DELETE FROM taxa WHERE id IN (?)", main_taxon_id)

# get the maximum id from the taxa table
taxa_id_offset = main_db_connection.execute("SELECT MAX(id) FROM taxa limit 1;").fetchone()[0]
genomes_id_offset = main_db_connection.execute("SELECT MAX(id) FROM genomes limit 1;").fetchone()[0]

# select all rows from patch_db_connection taxa table and add taxa_id_offset to the ID
for row in patch_db_connection.execute("SELECT * FROM taxa"):
    main_db_connection.execute("INSERT INTO taxa VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)", (row.id + taxa_id_offset, row.key, row.name, row.rank, row.description, row.distance_threshold, row.report, 1, row.parent_id + taxa_id_offset, row.ncbi_id))

# select all rows from patch_db_connection genomes table and add genomes_id_offset to the ID
for row in patch_db_connection.execute("SELECT * FROM genomes"):
    main_db_connection.execute("INSERT INTO genomes VALUES (?, ?, ?, ?, ?, ?)", (row.id + genomes_id_offset, row.key,  row.description, row.ncbi_db, row.ncbi_id, row.genbank_acc))

# select all rows from patch_db_connection genome_annotation table and add genomes_id_offset and taxa_id_offset to the ID
for row in patch_db_connection.execute("SELECT * FROM genome_annotation"):
    main_db_connection.execute("INSERT INTO genome_annotations VALUES (?, ?, ?, ?)", (row.genome_id + genomes_id_offset, row.genome_set_id, row.taxon_id + taxa_id_offset, row.organism))

# remove genomes from main signatures file - refactor to do it without an intermediate file.
from gambit.sigs import  load_signatures, dump_signatures, AnnotatedSignatures, SignatureList
# read in the signatures file, filter out the genome accessions we dont need and write a new file.
temp_main_signatures_filename = 'temp_main_signatures_filename.gs'
with load_signatures(options.signatures_main_filename) as src:
    in_gidxs = np.flatnonzero(~np.in1d(src.ids,genome_accessions_to_remove))
    filtered_src_ids = src.ids[in_gidxs]
    filtered_src = src[in_gidxs]
    out_sigs = AnnotatedSignatures(filtered_src, filtered_src_ids, src.meta)
    dump_signatures(temp_main_signatures_filename, out_sigs)

# merge the two signatures files
with load_signatures(temp_main_signatures_filename) as main_sig, load_signatures(options.signatures_patch_filename) as patch_sig:
    # merge the two signatures files
    merged_src_ids = np.concatenate((main_sig.ids, patch_sig.ids))
    merged_src = SignatureList(main_sig)
    merged_src.extend(patch_sig)
    out_sigs = AnnotatedSignatures(merged_src, merged_src_ids, main_sig.meta)
    dump_signatures(options.signatures_output_filename, out_sigs)

# delete temp_main_signatures_filename
os.remove(temp_main_signatures_filename)

# Save the main_db_connection database to a new file

# Close the connection
main_db_connection.close()
patch_db_connection.close()
