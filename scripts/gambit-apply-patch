#!/usr/bin/env python3
#./scripts/gambit-apply-patch --verbose --signatures_output_filename /home/michelle_scribner/gambit_patch/out.gs --database_output_filename /home/michelle_scribner/gambit_patch/out.gdb /home/michelle_scribner/gambit_patch/gambit-signatures-1.0b1-210719.h5 /home/michelle_scribner/gambit_patch/gambit-genomes-1.0b2-rev2-211116.db /home/michelle_scribner/gambit_patch/230417-theiagen-prok-patch-final.h5 /home/michelle_scribner/gambit_patch/230417-theiagen-prok-patch-final.db 
import argparse
import numpy as np
import sqlite3
import shutil
import logging
import os

parser = argparse.ArgumentParser(
    description = 'Given two Gambit signatures files, merge them and return a new file.',
    usage = 'gambit-merge-signatures [options]',
    formatter_class=argparse.ArgumentDefaultsHelpFormatter)

# Required input files
parser.add_argument('signatures_main_filename', help='A signatures .h5 file created by gambit signatures', type=str)
parser.add_argument('database_main_filename', help='An SQLite database', type=str)
parser.add_argument('signatures_patch_filename', help='A signatures .h5 file created by gambit signatures', type=str)
parser.add_argument('database_patch_filename', help='An SQLite database', type=str)

# Output
parser.add_argument('--signatures_output_filename', '-s', help='Output filename for genome signatures', default = 'patched_database.gs', type=str)
parser.add_argument('--database_output_filename', '-d', help='Output filename for database', default = 'patched_database.gdb', type=str)

parser.add_argument('--verbose', '-v', action='store_true', help='Turn on verbose output', default = False)
options = parser.parse_args()

# setup logging
if options.verbose:
    logging.basicConfig(level=logging.DEBUG)
else:
    logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('PatchDB')

# copy the database so we dont modify the original
logger.debug("Copy main database to: " + options.database_output_filename)
shutil.copy(options.database_main_filename, options.database_output_filename)

# Connect to the database
main_db_connection = sqlite3.connect(options.database_output_filename)
patch_db_connection = sqlite3.connect(options.database_patch_filename)

# Retrieve patch data
patch_genomes = [row[0] for row in patch_db_connection.execute("SELECT key FROM genomes")]
patch_taxa = [row[0] for row in patch_db_connection.execute("SELECT name FROM taxa")]
# remove taxa with changed names from prior database versions
patch_taxa_keys = [row[0] for row in patch_db_connection.execute("SELECT key FROM taxa")]
logger.debug("Patch contains " + str(len(patch_genomes)) + " genomes and " + str(len(patch_taxa)) + " taxa to be added")

# Output the number of rows in main DB
start_num_genomes = main_db_connection.execute("SELECT count(id) FROM genomes;").fetchone()[0]
logger.debug("The number of genomes in the main database before deletion is " + str(start_num_genomes))
start_num_taxa = main_db_connection.execute("SELECT count(id) FROM taxa;").fetchone()[0]
logger.debug("The number of taxa in the main database before deletion is " + str(start_num_taxa))

# Lookup main database for corresponding taxa and genomes
# we are going to delete rows so store the ids in a list to help with manipulations (could do a lot of this in join statements)
main_genome_id = [row[0] for row in main_db_connection.execute("SELECT genome_id FROM genome_annotations WHERE organism IN (" + str(','.join(['?' for _ in patch_taxa]))+ ")", patch_taxa)]
main_taxon_id = [row[0] for row in main_db_connection.execute("SELECT taxon_id FROM genome_annotations WHERE organism IN (" + str(','.join(['?' for _ in patch_taxa]))+ ")", patch_taxa)]
logger.debug("Based on the patch taxa, the main database contains " + str(len(main_genome_id)) + " genomes and " + str(len(main_taxon_id)) + " taxa to be removed first")

main_genome_accessions_to_remove = [row[0] for row in main_db_connection.execute("SELECT key FROM genomes WHERE key IN (" + str(','.join(['?' for _ in main_genome_id]))+ ")", main_genome_id)]
# merge the patch_genomes and main_genome_accessions_to_remove lists and remove duplicates
genome_accessions_to_remove = list(set(patch_genomes + main_genome_accessions_to_remove))

logger.debug("The total number of genomes to remove (when including the patch genomes) is " + str(len(genome_accessions_to_remove)))
main_genome_ids_to_remove = [row[0] for row in main_db_connection.execute("SELECT id FROM genomes WHERE key IN (" + str(','.join(['?' for _ in genome_accessions_to_remove]))+ ")", genome_accessions_to_remove)]

# remove genomes and taxa from main database
logger.debug("Deleting genomes, genome_annotations and taxa from main database")
cursor = main_db_connection.execute("DELETE FROM genomes WHERE id IN (" + str(','.join(['?' for _ in main_genome_ids_to_remove]))+ ")", main_genome_ids_to_remove)
logger.debug("Deleted "+ str(cursor.rowcount)+ " rows from the genomes table")
cursor = main_db_connection.execute("DELETE FROM genome_annotations WHERE genome_id IN (" + str(','.join(['?' for _ in main_genome_ids_to_remove]))+ ")", main_genome_ids_to_remove)
logger.debug("Deleted "+ str(cursor.rowcount)+ " rows from the genome_annotations table")
cursor = main_db_connection.execute("DELETE FROM genome_annotations WHERE taxon_id IN (" + str(','.join(['?' for _ in main_taxon_id]))+ ")", main_taxon_id)
logger.debug("Deleted "+ str(cursor.rowcount)+ " rows from the genome_annotations table")
cursor = main_db_connection.execute("DELETE FROM taxa WHERE id IN (" + str(','.join(['?' for _ in main_taxon_id]))+ ")", main_taxon_id)
logger.debug("Deleted "+ str(cursor.rowcount)+ " rows from the taxa table")
cursor = main_db_connection.execute("DELETE FROM taxa WHERE key IN (" + str(','.join(['?' for _ in patch_taxa_keys]))+ ")", patch_taxa_keys)
logger.debug("Deleted "+ str(cursor.rowcount)+ " rows from the taxa table where taxa name was changed from prior database versions")

# Output the number of rows after deletion so that you know if it worked in verbose mode.
post_delete_num_genomes = main_db_connection.execute("SELECT count(id) FROM genomes;").fetchone()[0]
logger.debug("The number of genomes in the main database after deletion is " + str(post_delete_num_genomes))
post_delete_num_taxa = main_db_connection.execute("SELECT count(id) FROM taxa;").fetchone()[0]
logger.debug("The number of taxa in the main database after deletion is " + str(post_delete_num_taxa))

# get the maximum id from the taxa table
taxa_id_offset = int(main_db_connection.execute("SELECT MAX(id) FROM taxa limit 1;").fetchone()[0])
genomes_id_offset = int(main_db_connection.execute("SELECT MAX(id) FROM genomes limit 1;").fetchone()[0])
logger.debug("The maximum ID in the main taxa table is " + str(taxa_id_offset) + " and this will be added to every taxa ID from the patch database")
logger.debug("The maximum ID in the main genomes table is " + str(genomes_id_offset) + " and this will be added to every genome ID from the patch database")

# select all rows from patch_db_connection taxa table and add taxa_id_offset to the ID
logger.debug("Add all the patch taxa rows to the main database")
for row in patch_db_connection.execute("SELECT * FROM taxa"):
    parent_taxon_id = '' if row[8] == '' or row[8] is None else int(row[8]) + taxa_id_offset
    main_db_connection.execute("INSERT INTO taxa VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)", (int(row[0]) + taxa_id_offset, row[1], row[2], row[3], row[4], row[5], row[6], row[7], parent_taxon_id, row[9], ''))

logger.debug("Add all the patch genome rows to the main database")
# select all rows from patch_db_connection genomes table and add genomes_id_offset to the ID
for row in patch_db_connection.execute("SELECT * FROM genomes"):
    # check if a row with the same genbank_acc value already exists in the table
    existing_row = main_db_connection.execute("SELECT * FROM genomes WHERE genbank_acc=?", (str(row[5]),)).fetchone()
    
    if existing_row is not None:
        # if a row with the same genbank_acc value exists, skip this row
        #logger.debug("Skipping genome with genbank_acc " + row[5] + " because it already exists in the main database")
        continue
    # if a row with the same genbank_acc value does not exist, insert the row
    main_db_connection.execute("INSERT INTO genomes VALUES (?, ?, ?, ?, ?, ?, ?, ?)", (int(row[0]) + genomes_id_offset, row[1],  row[2], row[3], row[4], row[5], None, None))

logger.debug("Add all the patch genome_annotations rows to the main database")
# select all rows from patch_db_connection genome_annotations table and add genomes_id_offset and taxa_id_offset to the ID
for row in patch_db_connection.execute("SELECT * FROM genome_annotations"):
    main_db_connection.execute("INSERT INTO genome_annotations VALUES (?, ?, ?, ?)", (int(row[0]) + genomes_id_offset, row[1], int(row[2]) + taxa_id_offset, row[3]))

# Output the number of inserted rows so that you know if it worked in verbose mode.
final_num_genomes = main_db_connection.execute("SELECT count(id) FROM genomes;").fetchone()[0]
logger.debug("The final number of genomes in the main database is " + str(final_num_genomes))
final_num_taxa = main_db_connection.execute("SELECT count(id) FROM taxa;").fetchone()[0]
logger.debug("The final number of taxa in the main database is " + str(final_num_taxa))

# remove genomes from main signatures file - refactor to do it without an intermediate file.
from gambit.sigs import  load_signatures, dump_signatures, AnnotatedSignatures, SignatureList
# read in the signatures file, filter out the genome accessions we dont need and write a new file.
temp_main_signatures_filename = 'temp_main_signatures_filename.gs'
logger.debug("Remove all the patch genomes from the main signatures file (so there are no name clashes later) and save to a temp file "+ str(temp_main_signatures_filename))
with load_signatures(options.signatures_main_filename) as src:
    in_gidxs = np.flatnonzero(~np.in1d(src.ids,genome_accessions_to_remove))
    filtered_src_ids = src.ids[in_gidxs]
    filtered_src = src[in_gidxs]
    out_sigs = AnnotatedSignatures(filtered_src, filtered_src_ids, src.meta)
    dump_signatures(temp_main_signatures_filename, out_sigs)

# merge the two signatures files
logger.debug("Merge the two signatures files saving to " + options.signatures_output_filename)
with load_signatures(temp_main_signatures_filename) as main_sig, load_signatures(options.signatures_patch_filename) as patch_sig:
    # merge the two signatures files
    merged_src_ids = np.concatenate((main_sig.ids, patch_sig.ids))
    merged_src = SignatureList(main_sig)
    merged_src.extend(patch_sig)
    out_sigs = AnnotatedSignatures(merged_src, merged_src_ids, main_sig.meta)
    dump_signatures(options.signatures_output_filename, out_sigs)

# delete temp_main_signatures_filename
os.remove(temp_main_signatures_filename)

# Commit connection
main_db_connection.commit()

# Close the connection
main_db_connection.close()
patch_db_connection.close()

logger.debug("Final patched database file: " + options.database_output_filename)
logger.debug("Final patched signatures file: " + options.signatures_output_filename)
